name: SBM — Data Fetch & Preflight

on:
  workflow_dispatch:
  schedule:
    - cron: "5 */6 * * *"   # every 6 hours

concurrency:
  group: sbm-data-preflight
  cancel-in-progress: false

permissions:
  contents: write

jobs:
  fetch-and-preflight:
    runs-on: ubuntu-latest
    timeout-minutes: 180
    env:
      PYTHONUNBUFFERED: "1"
      # RISK_HALT: "1"
      # ALLOW_EMPTY_SLATE: "0"   # set to "1" to bypass asserts (not recommended)

      # FBref config via repo Variables (read by the streamlined fetcher)
      FBREF_LEAGUE: ${{ vars.FBREF_LEAGUE }}
      FBREF_SEASONS: ${{ vars.FBREF_SEASONS }}
      FBREF_SLICES: ${{ vars.FBREF_SLICES }}

      # ---------- Optional discovery filters ----------
      # API_FOOTBALL_DISCOVER_COUNTRIES: ""
      API_FOOTBALL_DISCOVER_TYPE: "league"
      # API_FOOTBALL_DISCOVER_SEASONS: ""      # e.g. "2024,2025"
      MAX_DISCOVERED_LEAGUES: "60"

      # ---------- FBR limits (safe defaults) ----------
      FBR_MIN_INTERVAL_SEC: "6"
      FBR_MAX_CALLS_PER_MIN: "10"
      FBR_ENDPOINTS: "/leagues,/matches/upcoming,/matches/recent"
      FBR_OUT_DIR: "data/fbr"
      FBR_TIMEOUT_SEC: "30"
      FBR_RETRIES: "3"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt', 'audit/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Cache soccerdata (provider cache)
        uses: actions/cache@v4
        with:
          path: .cache/soccerdata
          key: ${{ runner.os }}-soccerdata-${{ env.FBREF_LEAGUE }}-${{ env.FBREF_SEASONS }}
          restore-keys: |
            ${{ runner.os }}-soccerdata-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f "requirements.txt" ]; then pip install -r requirements.txt; fi
          if [ -f "audit/requirements.txt" ]; then pip install -r audit/requirements.txt; fi
          mkdir -p data reports .cache/soccerdata

      # Ensure repo root on import path (connectors/, scripts/)
      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      # Map both teams' secret names -> canonical envs & presence check
      - name: Set env (common) & presence check
        env:
          APIFOOTBALL_KEY:       ${{ secrets.APIFOOTBALL_KEY }}
          API_FOOTBALL_KEY_S:    ${{ secrets.API_FOOTBALL_KEY }}
          FOOTBALLDATA_TOKEN:    ${{ secrets.FOOTBALLDATA_TOKEN }}
          FDORG_TOKEN_S:         ${{ secrets.FDORG_TOKEN }}
          THE_ODDS_API_KEY_S:    ${{ secrets.THE_ODDS_API_KEY }}
          ODDS_API_KEY_LEGACY:   ${{ secrets.ODDS_API_KEY }}
        run: |
          API_FOOTBALL_KEY="${API_FOOTBALL_KEY_S:-$APIFOOTBALL_KEY}"
          FDORG_TOKEN="${FDORG_TOKEN_S:-$FOOTBALLDATA_TOKEN}"
          THE_ODDS_API_KEY="${THE_ODDS_API_KEY_S:-$ODDS_API_KEY_LEGACY}"

          echo "API_FOOTBALL_KEY=${API_FOOTBALL_KEY}" >> $GITHUB_ENV
          echo "FDORG_TOKEN=${FDORG_TOKEN}"           >> $GITHUB_ENV
          echo "THE_ODDS_API_KEY=${THE_ODDS_API_KEY}" >> $GITHUB_ENV

          test -n "${API_FOOTBALL_KEY}" && echo "API_FOOTBALL_KEY: SET" || echo "API_FOOTBALL_KEY: NOT SET"
          test -n "${FDORG_TOKEN}"      && echo "FDORG_TOKEN: SET"      || echo "FDORG_TOKEN: NOT SET"
          test -n "${THE_ODDS_API_KEY}" && echo "THE_ODDS_API_KEY: SET" || echo "THE_ODDS_API_KEY: NOT SET"

      # Fail fast if required envs missing (preflight context)
      - name: Secret guard (preflight)
        run: python scripts/secret_guard.py --context=preflight

      # (Optional) FBR key if you use FBR API elsewhere
      - name: Generate FBR API key (ephemeral)
        run: python scripts/fbr_generate_api_key.py

      # ---------- Discover active API-Football leagues ----------
      - name: Discover leagues (API-Football)
        run: python connectors/api_football_discover_leagues.py

      # ---------------- FETCHERS ----------------

      - name: Fetch SPI (robust; ci_width)
        run: python connectors/spi_fetch.py

      - name: Fetch FBR API (rate-limited)
        run: python connectors/fbref_fetch_streamlined.py

      - name: Fetch FBref slices → data/fbref_slice_*.csv (retry)
        run: |
          set -e
          for i in 1 2 3; do
            echo "FBref slice fetch attempt $i..."
            python connectors/fbref_fetch_streamlined.py && break
            echo "FBref slice fetch attempt $i failed; sleeping before retry..."
            sleep $((30 * i))
          done

      - name: Fetch Odds + Fixtures (H2H + OU + BTTS + Spreads; two-key fallback)
        run: python connectors/multi_odds_fetch.py

      # ---------- FIXTURES RELIABILITY LAYER ----------
      - name: Ensure fixtures exist (API-FOOTBALL fallback)
        run: python connectors/fixtures_fallback_api_football.py

      - name: Persist opening/closing odds & line-moves
        run: python connectors/odds_open_close_capture.py

      - name: Fixtures debug probe
        run: python scripts/fixtures_debug_probe.py

      # Hard stop if still no fixtures after fallback (unless ALLOW_EMPTY_SLATE=1)
      - name: Assert fixtures present
        run: python scripts/sanity_assert.py --mode=fixtures

      - name: Attach API-FOOTBALL IDs to fixtures
        run: python connectors/api_football_attach_ids.py

      - name: League allowlist sync probe
        run: python scripts/league_sync_probe.py

      - name: Fetch lineups (availability + experienced starters %)
        run: python connectors/lineups_fetch.py

      # --------------- PRIORS + ENRICH ---------------
      - name: Build cards/corners priors
        run: python scripts/ref_cards_corners_build.py

      - name: Audit team/league mappings
        run: python scripts/mapping_audit.py

      - name: Enrich features (per-slice FBref + line moves)
        run: python scripts/enrich_features.py

      - name: Build schedule features (rest & density)
        run: python scripts/hist_schedule_features.py

      - name: Build rolling form (exp-decay)
        run: python scripts/rolling_form_exp_decay.py

      # --------------- MINI-PRIOR MODELS ---------------
      - name: Build xG prior (sim)
        run: python scripts/priors_xg_sim.py

      - name: Build availability prior
        run: python scripts/priors_availability.py

      - name: Build set-piece prior
        run: python scripts/priors_setpieces.py

      - name: Build market-move prior
        run: python scripts/priors_market_move.py

      - name: Build uncertainty prior
        run: python scripts/priors_uncertainty.py

      # --------------- FEATURES + RISK ---------------
      - name: Build feature diffs & coherence features
        run: python scripts/feature_patcher.py

      - name: Build extended consistency checks
        run: python scripts/consistency_checks_build.py

      - name: Update Kelly stakes by risk policy (liquidity tiers + caps)
        run: python scripts/kelly_policy_update.py

      - name: Log vetoed fixtures (WHY_NOT_BET)
        run: python scripts/why_not_bet.py

      - name: WHY_NOT_BET summary (grouped reasons)
        run: python scripts/why_not_bet_summary.py

      # --------------- HISTORY LOGGER ---------------
      - name: Append history log (run-time audit)
        env:
          GITHUB_RUN_ID: ${{ github.run_id }}
          GITHUB_WORKFLOW: ${{ github.workflow }}
        run: python scripts/history_logger.py

      # --------------- MODEL MATRIX ---------------
      - name: Build model-ready matrix
        run: python scripts/model_matrix_build.py

      - name: Validate model matrix schema
        run: python scripts/model_matrix_validate.py

      - name: Build calibration report
        run: python scripts/calibration_report_build.py

      # --------------- OPTIONAL TRAINERS ---------------
      - name: Train minimal model (rolling CV + per-league isotonic)
        run: python scripts/trainer_minimal.py

      - name: Train stack (base + priors + contradictions)
        run: python scripts/stack_trainer.py

      - name: Build feature-importance report
        run: python scripts/feature_importance_report.py

      # --------------- GUARDS / BRIEFING / DECK ---------------
      - name: Guard against blank artifacts
        env:
          BLANK_FAIL_CRITICAL: "0"
        run: python scripts/blank_file_guard.py

      - name: Append source alerts to AUTO_BRIEFING.md
        run: |
          mkdir -p reports
          if [ ! -f reports/AUTO_BRIEFING.md ] ; then echo "# AUTO BRIEFING" > reports/AUTO_BRIEFING.md ; fi
          python scripts/alerts_autobriefing_append.py
          {
            echo "";
            echo "## Odds Key Usage";
            if [ -f reports/ODDS_ALERTS.md ]; then
              echo "";
              echo "**From ODDS_ALERTS.md:**";
              cat reports/ODDS_ALERTS.md;
            else
              echo "- No ODDS_ALERTS.md found this run.";
            fi
            echo "";
          } >> reports/AUTO_BRIEFING.md

      - name: Append SLOs to briefing
        run: python scripts/preflight_slo_append.py

      - name: Post-run sanity summary
        run: python scripts/post_run_sanity.py

      - name: Forward coverage & gaps
        run: python scripts/forward_coverage_report.py

      - name: Deep sanity probe (file-by-file)
        run: python scripts/deep_sanity_probe.py

      - name: Connector health probe
        run: python scripts/connectors_health_probe.py

      - name: Build Council Deck (one-glance review)
        run: python scripts/council_deck_build.py

      - name: Upload data & reports
        uses: actions/upload-artifact@v4
        with:
          name: sbm-preflight-artifacts
          path: |
            data/*.csv
            data/*.parquet
            reports/*.md
            reports/*.csv
            reports/*.json